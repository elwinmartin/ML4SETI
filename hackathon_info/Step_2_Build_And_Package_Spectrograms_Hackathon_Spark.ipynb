{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build and Zip PNG Files - Hackathon\n",
    "\n",
    "In this notebook, we'll take the `basic` data set, use `ibmseti` Python package to convert each data file into a spectrogram, then save as `.png` files.\n",
    "\n",
    "\n",
    "Then, we'll split the data set into a training set and a test set and create a handful of zip files for each class. This will dovetail into the next tutorial where we will train a custom Watson Visual Recognition classifier (we will use the zip files of pngs) and measure it's performance with the test s\n",
    "\n",
    "## Spark Enterprise Cluster\n",
    "\n",
    "This notebook is currently written to run on the Spark Enterprise Cluster. That is, the variables point to the data locations on the Enterprise Cluster. \n",
    "\n",
    "#### PowerAI\n",
    "\n",
    "However, if you wish to run this on the PowerAI systems at the Hackathon, read cell 3 below. You only need to uncomment a few lines so that variables point to the data locations on the PowerAI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cStringIO\n",
    "import glob\n",
    "import json\n",
    "import requests\n",
    "import ibmseti\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "teamname = 'somedatafolder'\n",
    "\n",
    "mydatafolder = os.path.join( os.environ['PWD'], teamname )      \n",
    "\n",
    "# Create folder for zip to extract to\n",
    "setiDataDir = mydatafolder + '/data'\n",
    "if os.path.exists(setiDataDir) is False:\n",
    "    os.makedirs(setiDataDir)\n",
    "    \n",
    "# Create folder for future spectrograms\n",
    "outputpng_folder = mydatafolder + '/png'\n",
    "if os.path.exists(outputpng_folder) is False:\n",
    "    os.makedirs(outputpng_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract Data folder\n",
    "def unzip_data(zipf, dest):\n",
    "    # zipf = array of zip files     \n",
    "    for i in zipf:\n",
    "        zz = zipfile.ZipFile(mydatafolder + '/' + i )\n",
    "        zz.extractall(dest)\n",
    "    \n",
    "unzip_data(setiDataDir, ['basic4.zip'])\n",
    "\n",
    "# when using the larger dataset, you will have multiple zip files. Pass an array of those zip files to unzip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose your data set!\n",
    "workingDataDir = primarySetiDataDir\n",
    "workingIndexFile = os.path.join( mydatafolder + '/public_list_basic_v2_26may_2017.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Use `ibmseti`, or other methods, to draw the spectrograms\n",
    "\n",
    "def draw_spectrogram(data):\n",
    "    \n",
    "    aca = ibmseti.compamp.SimCompamp(data)\n",
    "    spec = aca.get_spectrogram()\n",
    "    \n",
    "    \n",
    "    # Instead of using SimCompAmp.get_spectrogram method\n",
    "    # perform your own signal processing here before you create the spectrogram\n",
    "    #\n",
    "    # SimCompAmp.get_spectrogram is relatively simple. Here's the code to reproduce it:\n",
    "    #\n",
    "    # header, raw_data = r.content.split('\\n',1)\n",
    "    # complex_data = np.frombuffer(raw_data, dtype='i1').astype(np.float32).view(np.complex64)\n",
    "    # complex_data = complex_data - complex_data.mean()  # have to subtract off any DC offset\n",
    "    # shape = (32, 6144)\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data.reshape(*shape) ), 1) )**2\n",
    "    # \n",
    "    # But instead of the line above, can you maniputlate `complex_data` with signal processing\n",
    "    # techniques in the time-domain (windowing?, de-chirp?), or manipulate the output of the \n",
    "    # np.fft.fft process in a way to improve the signal to noise (Welch periodogram, subtract noise model)? \n",
    "    # \n",
    "    # example: Apply Hanning Window\n",
    "    # complex_data = complex_data.reshape(*shape)\n",
    "    # complex_data = complex_data * np.hanning(complex_data.shape[1])\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data ), 1) )**2\n",
    "\n",
    "    \n",
    "    ## Noise Subtraction\n",
    "    #\n",
    "    #  If you are building an average noise spectrogram model for subtraction, you should do that here.\n",
    "    #\n",
    "    #  See the Example to build an average noise spectrogram: \n",
    "    #\n",
    "    #  Important point: If you do signal processing above to the raw data, you should apply the exact same signal processing\n",
    "    #     when you calculate your average noise spectrogram\n",
    "    #\n",
    "    #    import pickle\n",
    "    #    ave_noise_spec = pickle.load(os.path.join(mydatafolder, 'ave_noise_spec.pickle'))\n",
    "    #    spec = spec - ave_noise_spec\n",
    "    #\n",
    "    #\n",
    "     \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))   \n",
    "\n",
    "    # do different color mappings affect Watson's classification accuracy?\n",
    "    \n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='hot')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='Greys')\n",
    "    \n",
    "    ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    \n",
    "    ##\n",
    "    ## For other ways to create Images, see: \n",
    "    ## tutorials/Step_5c_Convert_TS_to_unit8Dataset_DSX.ipynb\n",
    "    ##\n",
    "    \n",
    "    return fig, aca.header()\n",
    "\n",
    "\n",
    "def convert_to_spectrogram_and_save(row):\n",
    "    \n",
    "    try:\n",
    "        uuid, classification = row.split(',')\n",
    "    except:\n",
    "        uuid = row #this handles the test data since it doesn't have \"SIGNAL_CLASSIFICATION\" in index file\n",
    "        classification = 'unknown: test data'\n",
    "        \n",
    "        \n",
    "    #create path to local data file\n",
    "    filename = uuid + '.dat'\n",
    "    filepath = os.path.join(workingDataDir, filename)\n",
    "    \n",
    "    #retrieve that data file\n",
    "    rawdata = open(filepath).read()\n",
    "    \n",
    "    \n",
    "    fig, header = draw_spectrogram(rawdata)\n",
    "    \n",
    "    png_file_name = filename + '.png'\n",
    "    fig.savefig( os.path.join(outputpng_folder, png_file_name) )\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return (filename, header, png_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile(workingIndexFile, 30).filter(lambda x: x.startswith('UUID') is False) #the filter removes the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = rdd.map(convert_to_spectrogram_and_save).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'b1cc342f-eae4-442b-91de-10c9a444072e.dat',\n",
       " {u'signal_classification': u'narrowband',\n",
       "  u'uuid': u'b1cc342f-eae4-442b-91de-10c9a444072e'},\n",
       " u'b1cc342f-eae4-442b-91de-10c9a444072e.dat.png')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Training / Test sets\n",
    "\n",
    "Using the `basic` list, we'll create training and test sets for each signal class. Then we'll archive the `.png` files into a handful of `.zip` files (We need the .zip files to be smaller than 25 MB each because there is a limitation with the size of batches of data that are uploaded to Watson Visual Recognition when training a classifier (200 MB total).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4000 files\n"
     ]
    }
   ],
   "source": [
    "# Grab the Basic file list in order to \n",
    "# Organize the Data into classes\n",
    "\n",
    "indexfile_rows = open(workingIndexFile).readlines()\n",
    "                                                    \n",
    "uuids_classes_as_list = indexfile_rows  [1:]#slice off the first line (header)\n",
    "\n",
    "def row_to_json(row):\n",
    "    uuid,sigclass = row.strip('\\n').split(',')  #strip \\n and split uuid, class\n",
    "    return {'uuid':uuid, 'signal_classification':sigclass}\n",
    "\n",
    "uuids_classes_as_list = map(lambda row: row_to_json(row), uuids_classes_as_list)\n",
    "print \"found {} files\".format(len(uuids_classes_as_list))\n",
    "\n",
    "uuids_group_by_class = {}\n",
    "for item in uuids_classes_as_list:\n",
    "    uuids_group_by_class.setdefault(item['signal_classification'], []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squiggle: training set size: 200\n",
      "squiggle: test set size: 100\n",
      "narrowband: training set size: 200\n",
      "narrowband: test set size: 100\n",
      "noise: training set size: 200\n",
      "noise: test set size: 100\n",
      "narrowbanddrd: training set size: 200\n",
      "narrowbanddrd: test set size: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#At first, use just 20 percent and 10 percent. This will be useful \n",
    "#as you prototype. You'll you use these to train Watson in the next notebook\n",
    "#So, if we only do the first 20 percent and 10 percent, we can move through\n",
    "#the tutorial quickly at first. Then you can come back here and increase these\n",
    "#percentages. \n",
    "training_percentage = 0.20\n",
    "test_percentage = 0.10\n",
    "\n",
    "assert training_percentage + test_percentage <= 1.0\n",
    "\n",
    "training_set_group_by_class = {}\n",
    "test_set_group_by_class = {}\n",
    "for k, v in uuids_group_by_class.iteritems():\n",
    "    \n",
    "    total = len(v)\n",
    "    training_size = int(total * training_percentage)\n",
    "    test_size = int(total * test_percentage)\n",
    "    \n",
    "    training_set = v[:training_size]\n",
    "    test_set = v[-1*test_size:]\n",
    "    \n",
    "    training_set_group_by_class[k] = training_set\n",
    "    test_set_group_by_class[k] = test_set\n",
    "    \n",
    "    print '{}: training set size: {}'.format(k, len(training_set))\n",
    "    print '{}: test set size: {}'.format(k, len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal_classification': 'noise',\n",
       " 'uuid': '498becc2-3693-45b3-8533-50e93532706a'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_group_by_class['noise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fnames = [ os.path.join(outputpng_folder, vv['uuid'] + '.dat.png') for vv in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure this looks right.\n",
    "# print fnames[0]\n",
    "# os.stat(fnames[0]).st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "zipfilefolder = mydatafolder + '/zipfiles'\n",
    "if os.path.exists(zipfilefolder) is False:\n",
    "    os.makedirs(zipfilefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_zip_file_size_in_mb = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_1_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_2_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_1_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_2_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_1_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_2_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_1_narrowbanddrd.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/classification_2_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "#Create the Zip files containing the training PNG files\n",
    "#Note that this limits output files to be less than <max_zip_file_size_in_mb> MB because WatsonVR has a limit on the \n",
    "#size of input files that can be sent in single HTTP calls to train a custom classifier\n",
    "\n",
    "for k, v, in training_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [ os.path.join(outputpng_folder, vv['uuid'] + '.dat.png') for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    count = 1\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/classification_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        \n",
    "        zz.write(fn, fn.split('/')[-1])\n",
    "        zz.close()\n",
    "        \n",
    "        #if archive_name folder exceeds <max_zip_file_size_in_mb> MB, increase count to create a new one\n",
    "        if os.path.getsize(archive_name) > max_zip_file_size_in_mb * 1024 ** 2:\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_1_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_1_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_1_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_1_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "#Create the Zip files containing the test PNG files\n",
    "#Note that this limits output files to be less than <max_zip_file_size_in_mb> MB because WatsonVR has a limit on the \n",
    "#size of input files that can be sent in single HTTP calls to train a custom classifier\n",
    "\n",
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    count = 1\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        \n",
    "        #if archive_name folder exceeds <max_zip_file_size_in_mb> MB, increase count to create a new one\n",
    "        if os.path.getsize(archive_name) > max_zip_file_size_in_mb * 1024 ** 2:\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_2_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_3_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_4_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_5_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_6_squiggle.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_2_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_3_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_4_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_5_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_6_narrowband.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_2_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_3_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_4_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_5_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_6_noise.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_2_narrowbanddrd.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_3_narrowbanddrd.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_4_narrowbanddrd.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_5_narrowbanddrd.zip\n",
      "creating new archive /home/ubuntu/somedatafolder/zipfiles/testset_6_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "# Create the Zip files containing the test PNG files using the following naming convention:\n",
    "# testset_<NUMBER>_<CLASS>.zip (step 4 will break if a different naming convention is used)\n",
    "# Refer to https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/#classify_an_image for ZIP size and content limitations:\n",
    "# \"The max number of images in a .zip file is limited to 20, and limited to 5 MB.\"\n",
    "\n",
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    # archive counter\n",
    "    count = 1\n",
    "    # number of image files in archive counter\n",
    "    image_count = 0\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            if os.path.getsize(archive_name) + os.path.getsize(fn) >= 4.9 * 1024 ** 2:\n",
    "                # current ZIP archive size + size of this file > max size (or at least close to); create new archive\n",
    "                count += 1\n",
    "                image_count = 0\n",
    "                archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "                print 'creating new archive', archive_name\n",
    "                zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "            else:\n",
    "                zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        \n",
    "        image_count += 1\n",
    "        # the number of files > max number of files supported by API; create new archive\n",
    "        if image_count > 19:\n",
    "            count +=1\n",
    "            image_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 304M\r\n",
      "drwxrwxr-x 2 ubuntu ubuntu 4.0K Jun 10 08:03 .\r\n",
      "drwxrwxr-x 5 ubuntu ubuntu 4.0K Jun 10 08:03 ..\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  26M Jun 10 08:03 classification_1_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  26M Jun 10 08:03 classification_1_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  26M Jun 10 08:03 classification_1_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  26M Jun 10 08:03 classification_1_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  13M Jun 10 08:03 classification_2_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  13M Jun 10 08:03 classification_2_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  14M Jun 10 08:03 classification_2_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  13M Jun 10 08:03 classification_2_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  19M Jun 10 08:03 testset_1_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  19M Jun 10 08:03 testset_1_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  20M Jun 10 08:03 testset_1_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  19M Jun 10 08:03 testset_1_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_2_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_2_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_2_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_2_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_3_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_3_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_3_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_3_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_4_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_4_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_4_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_4_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_5_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_5_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_5_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_5_squiggle.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_6_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_6_narrowband.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.9M Jun 10 08:03 testset_6_noise.zip\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3.8M Jun 10 08:03 testset_6_squiggle.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh \"$mydatafolder\"/zipfiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting your Zip files\n",
    "\n",
    "You do NOT need to do this if you're going on to the next notebook where you use Watson to classify your images from this Spark cluster. That notebook will read the data from here.\n",
    "\n",
    "However, if you want to move these data elsewhere, teasiest and fastest way to push your data out is to send it to your IBM Object Storage\n",
    "\n",
    "1. Log in to https://bluemix.net\n",
    "2. Scroll down and find your Object Storage instance. \n",
    "  * If you do not have one, find the \"Catalog\" link and look for the Object Storage service to create a new instance (5 GB of free space)\n",
    "3. Select the `Service Credentials` tab and `View Credentials`\n",
    "4. Copy these into your notebook below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import swiftclient.client as swiftclient\n",
    "\n",
    "credentials = {\n",
    "  'auth_uri':'',\n",
    "  'global_account_auth_uri':'',\n",
    "  'username':'xx',\n",
    "  'password':\"xx\",\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'xx',\n",
    "  'projectId':'xx',\n",
    "  'region':'dallas',\n",
    "  'userId':'xx',\n",
    "  'domain_id':'xx',\n",
    "  'domain_name':'xx',\n",
    "  'tenantId':'xx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_seti_data = swiftclient.Connection(\n",
    "    key=creds_seti_public['password'],\n",
    "    authurl=creds_seti_public['auth_url']+\"/v3\",\n",
    "    auth_version='3',\n",
    "    os_options={\n",
    "        \"project_id\": creds_seti_public['projectId'],\n",
    "        \"user_id\": creds_seti_public['userId'],\n",
    "        \"region_name\": creds_seti_public['region']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myObjectStorageContainer = 'example_pngs'  \n",
    "conn_seti_data.post_container(myObjectStorageContainer)  #creates a new container in your object storage\n",
    "\n",
    "someFile = os.path.join(zipfilefolder, 'classification_1_narrowband.zip')\n",
    "\n",
    "etag = conn_seti_data.put_object(myObjectStorageContainer, someFile, open(someFile,'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
