{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Watson Visual Recognition Training with Spectrogram Images from SETI Signal Data\n",
    "\n",
    "* https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/\n",
    "* https://www.ibm.com/watson/developercloud/doc/visual-recognition/customizing.html\n",
    "* https://github.com/watson-developer-cloud/python-sdk\n",
    "* https://github.com/watson-developer-cloud/python-sdk/blob/master/watson_developer_cloud/visual_recognition_v3.py\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Install the Watson Developer Cloud Python SDK\n",
    "\n",
    "* Install the Python SDK if has not been previously installed **`!pip install --upgrade watson-developer-cloud`**\n",
    "* Restart the kernel, after installing the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade watson-developer-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: YOU MUST READ THIS.\n",
    "\n",
    "ALL TEAMS WILL BE SHARING A WATSON API KEY FOR THIS WEEKEND. \n",
    "\n",
    "THIS MEANS IT IS POSSIBLE FOR YOU TO ACCIDENTALLY DELETE ANOTHER TEAM'S CLASSIFIER. THIS IS BAD. DO NOT DO THIS.\n",
    "\n",
    "IF YOU NEED TO DELETE YOUR OWN CLASSIFIER IN ORDER TO START OVER, WHICH YOU MIGHT WANT TO DO, YOU CAN RUN THE CODE BELOW THAT DOES THIS, BUT DO NOT MODIFY THAT CODE. THAT CODE WILL CREATE AND DELETE YOUR TEAM'S CLASSIFIER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Making a local folder to put my data.\n",
    "\n",
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "teamname = \n",
    "\n",
    "mydatafolder = os.path.join( os.environ['PWD'], teamname )  \n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    raise Exception('This folder needs to already exist. See the Build_And_Package_Spectrograms_HackathonSpark notebook')\n",
    "    \n",
    "    \n",
    "zipfilefolder = mydatafolder + '/zipfiles'\n",
    "if os.path.exists(zipfilefolder) is False:\n",
    "    raise Exception('This folder needs to already exist. See the Build_And_Package_Spectrograms_HackathonSpark notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "apiVer = VisualRecognitionV3.latest_version #'2016-05-20'\n",
    "classifier_prefix = teamname + \"_v1_\"\n",
    "\n",
    "#You can sign up with WatsonVR through Bluemix to get a key\n",
    "#However, Hackathon participants will be provided with a WATSON VR key that has more free API calls per day.\n",
    "apiKey = 'WATSON-VISUAL-RECOGNITION-API-KEY'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "apiKey = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls $mydatafolder/zipfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cStringIO\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import timeit\n",
    "import zipfile\n",
    "import copy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ibmseti\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Init the Watson Visual Recognition Python Library\n",
    "\n",
    "* you may need to install the SDK first: **`!pip install --upgrade watson-developer-cloud`**\n",
    "* you will need the **API** key from the Watson Visual Recognition Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vr = VisualRecognitionV3(apiVer, api_key=apiKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Look For Existing Custom Classifier\n",
    "Use an existing custom classifier (and update) if one exists, else a new custom classifier will be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING: This next cell will delete custom classifiers\n",
    "# DO NOT DELETE OTHER TEAM'S CLASSIFIERS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Run this cell ONLY IF you want to REMOVE your classifiers\n",
    "# Otherwise, the subsequent cell will append images to the `classifier_prefix` classifier\n",
    "\n",
    "## You can run this code below. It will delete a custom classifer that startswith your 'classifier_prefix', which is\n",
    "#    based on your teamname. \n",
    "\n",
    "# You can uncomment and run this code, but do NOT modify it. \n",
    "\n",
    "# If you have problems deleting your classifer, talk to an IBMer\n",
    "\n",
    "# classifiers = vr.list_classifiers()\n",
    "# for c in classifiers['classifiers']:\n",
    "#     if c['classifier_id'].startswith(classifier_prefix):\n",
    "#         vr.delete_classifier(c['classifier_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Find the classifier ID for your latest TEAMNAME classifier if it already exists\n",
    "\n",
    "classifier_id = None\n",
    "classifier = None\n",
    "\n",
    "classifiers = vr.list_classifiers()\n",
    "\n",
    "for c in classifiers['classifiers']:\n",
    "    if c['status'] == 'ready' and (classifier_prefix in c['classifier_id']):\n",
    "        classifier_id = c['classifier_id']\n",
    "\n",
    "\n",
    "if classifier_id is not None:\n",
    "    classifier = vr.get_classifier(classifier_id)\n",
    "    print '\\r\\nFound classifer:\\r\\n\\r\\n{}'.format(json.dumps(classifier, indent=2))\n",
    "else:\n",
    "    print 'No custom classifier available\\r\\n'\n",
    "    print(json.dumps(classifiers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Send the Images Archives to the Watson Visual Recognition Service for Training\n",
    "\n",
    "* https://www.ibm.com/watson/developercloud/doc/visual-recognition/customizing.html\n",
    "* https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/\n",
    "* https://github.com/watson-developer-cloud/python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "squiggle = sorted(glob.glob('{}/classification_*_squiggle.zip'.format(zipfilefolder)))\n",
    "narrowband = sorted(glob.glob('{}/classification_*_narrowband.zip'.format(zipfilefolder)))\n",
    "narrowbanddrd = sorted(glob.glob('{}/classification_*_narrowbanddrd.zip'.format(zipfilefolder)))\n",
    "noise = sorted(glob.glob('{}/classification_*_noise.zip'.format(zipfilefolder)))\n",
    "#brightpixel = sorted(glob.glob('{}/classification_*_brightpixel.zip'.format(zipfilefolder)))\n",
    "#squarepulsednarrowband = sorted(glob.glob('{}/classification_*_squarepulsednarrowband.zip'.format(zipfilefolder)))\n",
    "#squigglesquarepulsednarrowband = sorted(glob.glob('{}/classification_*_squigglesquarepulsednarrowband.zip'.format(zipfilefolder)))\n",
    "\n",
    "sq = len(squiggle)\n",
    "nb = len(narrowband)\n",
    "nd = len(narrowbanddrd)\n",
    "ns = len(noise)\n",
    "#nbp = len(brightpixel)\n",
    "#nsp = len(squarepulsednarrowband)\n",
    "#nss = len(squigglesquarepulsednarrowband)\n",
    "\n",
    "## Possible todo here: Try using the 'noise' as a \"negative\" example when training Watson. See the Watson documentation.\n",
    "\n",
    "## for prototyping. \n",
    "num = 2\n",
    "#num = max(sq, nb, nd, ns)\n",
    "\n",
    "\n",
    "if classifier_id is None:\n",
    "    print 'Adding custom classifier ... this may take awhile'\n",
    "else:\n",
    "    print 'Updating custom classifier {} ... this may take awhile'.format(classifier_id)\n",
    "\n",
    "for i in range(num):\n",
    "    squiggle_p = open(squiggle[i], 'rb') if i < sq else None\n",
    "    narrowband_p = open(narrowband[i], 'rb') if i < nb else None\n",
    "    narrowbanddrd_p = open(narrowbanddrd[i], 'rb') if i < nd else None\n",
    "    noise_p = open(noise[i], 'rb') if i < ns else None\n",
    "    #brightpixel_p = open(brightpixel[i], 'rb') if i < nb else None\n",
    "    #squarepulsednarrowband_p = open(squarepulsednarrowband[i], 'rb') if i < nd else None\n",
    "    #squigglesquarepulsednarrowband_p = open(squigglesquarepulsednarrowband[i], 'rb') if i < ns else None\n",
    "    \n",
    "\n",
    "    if classifier_id is None:\n",
    "        print 'Creating new classifier. Batch {}'.format(i)\n",
    "        classifier = vr.create_classifier(\n",
    "            classifier_prefix,\n",
    "            squiggle_positive_examples = squiggle_p,\n",
    "            narrowband_positive_examples = narrowband_p,\n",
    "            narrowbanddrd_positive_examples = narrowbanddrd_p,\n",
    "            noise_positive_examples = noise_p\n",
    "            #brightpixel_positive_examples = brightpixel_p,\n",
    "            #squarepulsednarrowband_positive_examples = squarepulsednarrowband_p,\n",
    "            #squigglesquarepulsednarrowband_positive_examples = squigglesquarepulsednarrowband_p\n",
    "        )\n",
    "        \n",
    "        classifier_id = classifier['classifier_id']\n",
    "    else:\n",
    "        print 'Updating classifier. Batch {}'.format(i)\n",
    "        classifier = vr.update_classifier(\n",
    "            classifier_id,\n",
    "            squiggle_positive_examples = squiggle_p,\n",
    "            narrowband_positive_examples = narrowband_p,\n",
    "            narrowbanddrd_positive_examples = narrowbanddrd_p,\n",
    "            noise_positive_examples = noise_p\n",
    "            #brightpixel_positive_examples = brightpixel_p,\n",
    "            #squarepulsednarrowband_positive_examples = squarepulsednarrowband_p,\n",
    "            #squigglesquarepulsednarrowband_positive_examples = squigglesquarepulsednarrowband_p \n",
    "        )\n",
    "\n",
    "    if squiggle_p is not None:\n",
    "        squiggle_p.close()\n",
    "    if narrowband_p is not None:\n",
    "        narrowband_p.close()\n",
    "    if narrowbanddrd_p is not None:\n",
    "        narrowbanddrd_p.close()\n",
    "    if noise_p is not None:\n",
    "        noise_p.close()\n",
    "    #if brightpixel_p is not None:\n",
    "    #    brightpixel_p.close()\n",
    "    #if squarepulsednarrowband_p is not None:\n",
    "    #    squarepulsednarrowband_p.close()\n",
    "    #if squigglesquarepulsednarrowband_p is not None:\n",
    "    #    squigglesquarepulsednarrowband_p.close()\n",
    "\n",
    "    if classifier is not None:\n",
    "        print('Classifier: {}'.format(classifier_id))\n",
    "        status = classifier['status']\n",
    "        startTimer = timeit.default_timer()\n",
    "        while status in ['training', 'retraining']:\n",
    "            print('Status: {}'.format(status))\n",
    "            time.sleep(10)\n",
    "            classifier = vr.get_classifier(classifier_id)\n",
    "            status = classifier['status']\n",
    "        stopTimer = timeit.default_timer()\n",
    "        print '{} took {} minutes'.format('Training' if i == 0 else 'Retraining', int(stopTimer - startTimer) / 60)\n",
    "\n",
    "print(json.dumps(vr.get_classifier(classifier_id), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Take a Random Data File for Testing\n",
    "\n",
    "* Take a random data file from the test set\n",
    "* Create a Spectrogram Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "zz = zipfile.ZipFile(zipfilefolder + '/' + 'testset_1_narrowband.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_list = zz.namelist()\n",
    "randomSignal = zz.open(test_list[9],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "squigImg = randomSignal.read()\n",
    "Image(squigImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#note - have to 'open' this again because it was already .read() out in the line above\n",
    "randomSignal = zz.open(test_list[10],'r')\n",
    "\n",
    "url_result = vr.classify(images_file=randomSignal, classifier_ids=classifier_id, threshold=0.0)\n",
    "\n",
    "print(json.dumps(url_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Run the Complete Test Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create a dictionary object to store results from Watson\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class_list = ['squiggle', 'noise', 'narrowband', 'narrowbanddrd']\n",
    "\n",
    "results_group_by_class = {}\n",
    "for classification in class_list:\n",
    "    results_group_by_class[classification] = defaultdict(list)\n",
    "    \n",
    "failed_to_classify_uuid_list = []\n",
    "\n",
    "print classifier_id\n",
    "\n",
    "results_group_by_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# locate test archives that were produced in step 3 and add them to the test set\n",
    "test_set = []\n",
    "for classification in class_list:\n",
    "    test_set = np.concatenate((test_set, sorted(glob.glob('{}/testset_*_{}.zip'.format(zipfilefolder, classification)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for image_archive_name in test_set:\n",
    "    image_count = 0\n",
    "    # count number of images in <image_archive_name>\n",
    "    with zipfile.ZipFile(image_archive_name,'r') as image_archive:\n",
    "        images = image_archive.namelist()\n",
    "        image_count = len(images)\n",
    "\n",
    "    # bulk classify images in <image_archive_name>\n",
    "    with open(image_archive_name, 'rb') as images_file:\n",
    "        print 'Running test ({} images) for {}... this may take a while.'.format(image_count, image_archive_name)\n",
    "        startTimer = timeit.default_timer()\n",
    "        classify_results = vr.classify(images_file=images_file, classifier_ids=[classifier_id], threshold=0.0)\n",
    "        # print(json.dumps(classify_results, indent=2))\n",
    "        # identify class from ZIP file name, e.g. testset_10_squiggle.zip\n",
    "        mo = re.match('^(.+)_(\\d+)_(.+)\\.zip$',image_archive_name.split('/')[-1])\n",
    "        classification = mo.group(3)\n",
    "        resdict = results_group_by_class[classification]\n",
    "        passed = 0\n",
    "            \n",
    "        for classify_result in classify_results['images']:\n",
    "            pngfilename = classify_result['image'].split('/')[-1]\n",
    "            uuid = pngfilename.split('.')[0]\n",
    "                \n",
    "            maxscore = 0\n",
    "            maxscoreclass = None\n",
    "\n",
    "            if \"error\" in classify_result:\n",
    "                # print error information\n",
    "                print classify_result\n",
    "                #add to failed list\n",
    "                failed_to_classify_uuid_list.append(uuid)                  \n",
    "            else:\n",
    "                classifiers_arr = classify_result['classifiers']\n",
    "                score_list = []\n",
    "                for classifier_result in classifiers_arr:\n",
    "                    for class_result in classifier_result['classes']:\n",
    "                        score_list.append((class_result['class'],class_result['score']))\n",
    "                        if class_result['score'] > maxscore:\n",
    "                            maxscore = class_result['score']\n",
    "                            maxscoreclass = class_result['class']\n",
    "                            \n",
    "                #sort alphabetically\n",
    "                score_list.sort(key = lambda x: x[0])\n",
    "                score_list = map(lambda x:x[1], score_list)\n",
    "                        \n",
    "                if maxscoreclass is None:\n",
    "                    print 'Failed: {} - Actual: {}, No classification returned'.format(pngfilename, classification)\n",
    "                    #print(json.dumps(classify_result, indent=2))\n",
    "                elif maxscoreclass != classification:\n",
    "                    print 'Failed: {} - Actual: {}, Watson Predicted: {} ({})'.format(pngfilename, classification, maxscoreclass, maxscore)\n",
    "                else:\n",
    "                    passed += 1\n",
    "                    print 'Passed: {} - Actual: {}, Watson Predicted: {} ({})'.format(pngfilename, classification, maxscoreclass, maxscore)\n",
    "\n",
    "                if maxscoreclass is not None:\n",
    "                    resdict['signal_classification'].append(classification)\n",
    "                    resdict['uuid'].append(uuid)\n",
    "                    resdict['watson_class'].append(maxscoreclass)\n",
    "                    resdict['watson_class_score'].append(maxscore)\n",
    "                    resdict['scores'].append(score_list)\n",
    "                else:\n",
    "                    #add to failed list\n",
    "                    failed_to_classify_uuid_list.append(uuid)                \n",
    "           \n",
    "        stopTimer = timeit.default_timer()\n",
    "        \n",
    "        print 'Test Score: {}% ({} of {} Passed)'.format(int((float(passed) / image_count) * 100), passed, image_count)\n",
    "        print 'Tested {} images in {} minutes'.format(image_count, int(stopTimer - startTimer) / 60)\n",
    "        \n",
    "print \"DONE.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results_group_by_class, open(mydatafolder + '/' + \"watson_results.pickle\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "watson_results = pickle.load(open(mydatafolder + '/' + \"watson_results.pickle\",\"r\"))\n",
    "# reorganize the watson_results dictionary to extract\n",
    "# a list of [true_class, [scores], estimated_class] and\n",
    "# use these for measuring our model's performance\n",
    "\n",
    "class_scores = []\n",
    "for k in watson_results.keys():\n",
    "    class_scores += zip(watson_results[k]['uuid'], watson_results[k]['signal_classification'], watson_results[k]['scores'], watson_results[k]['watson_class'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_scores[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "\n",
    "y_train = [x[1] for x in class_scores]\n",
    "y_pred = [x[3] for x in class_scores]\n",
    "y_prob = [x[2] for x in class_scores]\n",
    "#we normalize the Watson score values to 1 in order to use them in the log_loss calculation even though the Watson VR scores are not true class prediction probabilities\n",
    "y_prob = map(lambda x: (x, sum(x)), y_prob)\n",
    "y_prob = map(lambda x: [y / x[1] for y in x[0]], y_prob)\n",
    "\n",
    "print sklearn.metrics.classification_report(y_train,y_pred)\n",
    "print sklearn.metrics.confusion_matrix(y_train,y_pred)\n",
    "print(\"Classification accuracy: %0.6f\" % sklearn.metrics.accuracy_score(y_train,y_pred) )\n",
    "print(\"Log Loss: %0.6f\" % sklearn.metrics.log_loss(y_train,y_prob) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate CSV file for Scoreboard\n",
    "\n",
    "Here's an example of what the CSV file should look like for submission to the scoreboard. Although, in this case, we only have 4 classes instead of 7.\n",
    "\n",
    "#### NOTE: This uses the PNG files created in the Step 3 notebook, which only contain the BASIC4 data set. The code challenge and hackathon will be based on the Primary Data Set which contains 7 signal classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "my_output_results = mydatafolder + '/' + 'watson_scores.csv'\n",
    "with open(my_output_results, 'w') as csvfile:\n",
    "    fwriter = csv.writer(csvfile, delimiter=',')\n",
    "    for row in class_scores:\n",
    "        fwriter.writerow([row[0]] + row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print out the first 10 lines just to show it makes sense\n",
    "\n",
    "!head -n 10 $mydatafolder/watson_scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "  'auth_uri':'',\n",
    "  'global_account_auth_uri':'',\n",
    "  'username':'xx',\n",
    "  'password':\"xx\",\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'xx',\n",
    "  'project_id':'xx',\n",
    "  'region':'dallas',\n",
    "  'user_id':'xx',\n",
    "  'domain_id':'xx',\n",
    "  'domain_name':'xx',\n",
    "  'tenantId':'xx'\n",
    "}\n",
    "\n",
    "import swiftclient.client as swiftclient\n",
    "\n",
    "conn = swiftclient.Connection(\n",
    "    key=credentials['password'],\n",
    "    authurl=credentials['auth_url']+\"/v3\",\n",
    "    auth_version='3',\n",
    "    os_options={\n",
    "        \"project_id\": credentials['project_id'],\n",
    "        \"user_id\": credentials['user_id'],\n",
    "        \"region_name\": credentials['region']})\n",
    "\n",
    "myObjectStorageContainer = 'hackathon_scores'  \n",
    "conn_seti_data.post_container(myObjectStorageContainer)  #creates a new container in your object storage\n",
    "\n",
    "#classification_results_file = 'my_team_name_data_folder/results/my_final_testset_classes.csv'\n",
    "etag = conn.put_object(myObjectStorageContainer, 'watson_scores.csv', open(my_output_results).read())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
